{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2221d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126a18a",
   "metadata": {},
   "source": [
    "First, we will generate data from the different variables listed using a random variable customizer (obviously our actual model will have some accurate datapoints lol I'm just too lazy to clean data rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4441674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Community': ['Santee', 'Poway', 'La Jolla', 'Chula Vista', 'Escondido', 'El Cajon', 'Oceanside', 'Encinitas', \n",
    "                  'Carlsbad', 'San Ysidro', 'Vista', 'National City'],\n",
    "    'Proportion_Adults': np.random.uniform(0.5, 0.8, 12),\n",
    "    'Proportion_Seniors': np.random.uniform(0.1, 0.3, 12),\n",
    "    'Proportion_Children': np.random.uniform(0.2, 0.4, 12),\n",
    "    'Labor_Force_16_and_Over': np.random.uniform(0.6, 0.8, 12),\n",
    "    'Proportion_Females': np.random.uniform(0.4, 0.6, 12),\n",
    "    'Children_Single_Parent_Household': np.random.uniform(0.1, 0.3, 12),\n",
    "    'Families_Below_Poverty': np.random.uniform(0.1, 0.4, 12),\n",
    "    'Employment_Status': np.random.uniform(0.7, 0.9, 12),\n",
    "    'Recorded_Overdoses': np.random.randint(10, 100, 12),\n",
    "    'Proportion_Unhoused': np.random.uniform(0.01, 0.1, 12),\n",
    "    'Healthcare_Facilities': np.random.randint(1, 5, 12),\n",
    "    'Urban_Rural': np.random.choice([0, 1], 12),  # 0 for urban, 1 for rural\n",
    "    'Opioid_Prescription_Rates': np.random.uniform(0.1, 0.3, 12),\n",
    "    'Drug_Related_Arrests': np.random.randint(10, 50, 12)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a35394",
   "metadata": {},
   "source": [
    "Now, let's put it into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286b7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc974571",
   "metadata": {},
   "source": [
    "Our target variable of measurement is the \"at risk\" population of experiencing opiate overdoses. This will allow government agencies and healthcare professionals to calculate narcan demand across various communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02b4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['At_Risk_Count'] = np.random.randint(50, 500, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876a1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Community', 'At_Risk_Count'], axis=1)\n",
    "y = df['At_Risk_Count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b03928",
   "metadata": {},
   "source": [
    "Now, we will train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4315b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8772102",
   "metadata": {},
   "outputs": [
    {
    
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd37976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0a2a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_predictions = pd.DataFrame({\n",
    "    'Community': df['Community'].iloc[X_test.index],\n",
    "    'Actual_At_Risk_Count': y_test,\n",
    "    'Predicted_At_Risk_Count': predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863396d",
   "metadata": {},
   "source": [
    "We can visualize model predictions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8c107b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Community  Actual_At_Risk_Count  Predicted_At_Risk_Count\n",
      "10       Vista                   355                   162.08\n",
      "9   San Ysidro                   192                   141.98\n",
      "0       Santee                    58                   224.26\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "print(df_with_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b120ef96",
   "metadata": {},
   "source": [
    "CHECK THE FINAL DOC FOR THE FULLY EXPANDED VERSION OF THE MODEL I WANNA CREATE (includes generating lots of data including an independent variable for time & extrapolating trends (to get a predicted at risk count)which is like a form of pattern recognition i learned in econ lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667abab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
